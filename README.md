# Emotion Classification in Audio using CNNs and RNNs
## Description
<p>This repository contains the implementation and research findings of a project focused on emotion categorization using Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs) applied to audio data. The project explores the automatic extraction of significant features from audio signals to achieve robust emotion classification, with applications in virtual assistants, healthcare, and entertainment.</p>

## Model Architecture

<p>The proposed model architecture combines CNNs and RNNs to leverage spatial and temporal features in audio data. CNN layers focus on spatial feature extraction, while LSTM layers handle temporal feature learning. The integration allows for spatial-temporal fusion, enhancing the model's ability to capture both spatial and temporal aspects of audio data.</p>

![model_plot](https://github.com/AdityaSharma2485/emotion_classification/assets/92670331/cebc9da1-8642-4b91-b5ee-c1168b8ccab1)

## Implementation and Evaluation

![image](https://github.com/AdityaSharma2485/emotion_classification/assets/92670331/810f262d-5906-475b-acbe-fcde4de377dd)


